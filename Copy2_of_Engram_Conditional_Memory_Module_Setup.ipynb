{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh7OyKq0K23ibdDp0vp4pc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weagan/Engram/blob/main/Copy2_of_Engram_Conditional_Memory_Module_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOaM79sX72tR",
        "outputId": "35245d83-31fc-48e6-c676-4efd2fdf8f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Output shape: torch.Size([2, 8, 512])\n"
          ]
        }
      ],
      "source": [
        "# Cell gOaM79sX72tR\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EngramModule(nn.Module):\n",
        "    def __init__(self, table_size=100000, d_model=512, n_heads=4):\n",
        "        super().__init__()\n",
        "        self.table_size = table_size\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        # The Static Memory table\n",
        "        self.memory_table = nn.Parameter(torch.randn(table_size, d_model))\n",
        "\n",
        "        # Context-Aware Gating\n",
        "        self.gate = nn.Linear(d_model, 1)\n",
        "\n",
        "        # Multi-head projection\n",
        "        self.merge_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def multi_head_hash(self, input_ids):\n",
        "        \"\"\"Generates O(1) indices for the memory table\"\"\"\n",
        "        # We create different 'views' of the memory per head\n",
        "        hashes = [(input_ids * (i + 13)) % self.table_size for i in range(self.n_heads)]\n",
        "        return torch.stack(hashes, dim=-1) # [Batch, Seq, Heads]\n",
        "\n",
        "    # FIXED: Added 'def' here\n",
        "    def forward(self, hidden_states, input_ids):\n",
        "        batch_size, seq_len, _ = hidden_states.shape\n",
        "\n",
        "        # Get indices\n",
        "        indices = self.multi_head_hash(input_ids)\n",
        "\n",
        "        # Retrieve from Memory Table using functional embedding for speed\n",
        "        # We flatten to look up, then reshape back\n",
        "        retrieved_mem = F.embedding(indices, self.memory_table) # [B, S, n_heads, d_model]\n",
        "\n",
        "        # Aggregate the heads (Simple mean)\n",
        "        retrieved_mem = retrieved_mem.mean(dim=2)\n",
        "\n",
        "        # Apply Gating\n",
        "        gate_score = torch.sigmoid(self.gate(hidden_states))\n",
        "        gated_memory = retrieved_mem * gate_score\n",
        "\n",
        "        # Merge back into the Transformer stream\n",
        "        output = hidden_states + self.merge_proj(gated_memory)\n",
        "        return output\n",
        "\n",
        "# --- Verification ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = EngramModule(n_heads=1).to(device)\n",
        "\n",
        "# Mock inputs\n",
        "mock_ids = torch.randint(0, 1000, (2, 8)).to(device)\n",
        "mock_hidden = torch.randn(2, 8, 512).to(device)\n",
        "\n",
        "# Test forward pass\n",
        "out = model(mock_hidden, mock_ids)\n",
        "print(f\"Success! Output shape: {out.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88998a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2519a5-3c61-4189-bebd-3536544fbe88"
      },
      "source": [
        "# Cell 88998a27\n",
        "print('Demonstrating the value of EngramModule:')\n",
        "\n",
        "# 1. Manually set specific entries in the memory_table\n",
        "#    For demonstration, we'll set a few distinct patterns.\n",
        "#    We use .data to modify the underlying tensor of the nn.Parameter directly.\n",
        "#    With n_heads=1, multi_head_hash for input_id 'x' is (x * 13) % table_size.\n",
        "model.memory_table.data[0, :] = 1.0  # input_id 0 -> index 0\n",
        "model.memory_table.data[13, :] = 0.0 # input_id 1 -> index 13\n",
        "model.memory_table.data[26, :] = -1.0 # input_id 2 -> index 26\n",
        "\n",
        "print(\"Memory table entries 0, 13, and 26 have been set to distinct values.\")\n",
        "\n",
        "# --- Modify gate and merge_proj to be identity for direct observation ---\n",
        "# Modify the gate to effectively be an identity (output ~1.0 after sigmoid)\n",
        "# Set weights to 0 and bias to a large positive number\n",
        "model.gate.weight.data.zero_()\n",
        "model.gate.bias.data.fill_(10.0) # Large bias -> sigmoid output close to 1\n",
        "\n",
        "# Modify the merge_proj to be an identity mapping\n",
        "# Set weight to identity matrix and bias to zero\n",
        "model.merge_proj.weight.data.copy_(torch.eye(model.d_model))\n",
        "model.merge_proj.bias.data.zero_()\n",
        "print(\"Gating and Merge Projection modified to be identity mappings.\")\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# 2. Prepare mock inputs\n",
        "#    - mock_hidden: neutral (all zeros) hidden states\n",
        "#    - mock_ids: input IDs that will query the specific memory locations we set\n",
        "mock_hidden_demo = torch.zeros(1, 3, model.d_model).to(device) # Batch=1, Seq=3\n",
        "mock_ids_demo = torch.tensor([[0, 1, 2]]).to(device) # Query input_ids 0, 1, 2\n",
        "\n",
        "print(f\"Initial mock hidden state (first element of first item): {mock_hidden_demo[0, 0, 0].item():.4f}\")\n",
        "print(f\"Mock input IDs: {mock_ids_demo.tolist()}\")\n",
        "\n",
        "# 3. Perform forward pass\n",
        "output_demo = model(mock_hidden_demo, mock_ids_demo)\n",
        "\n",
        "# 4. Analyze output\n",
        "#    We expect the output to reflect the values from the memory table, especially\n",
        "#    since the initial hidden_states were zeros and the gate should allow information flow.\n",
        "\n",
        "print(\"\\nOutput after EngramModule forward pass:\")\n",
        "print(\"--------------------------------------\")\n",
        "\n",
        "# Print a slice of the output to observe the influence\n",
        "# For input_id=0, we expect output to be influenced by 'all ones'\n",
        "print(f\"Output for input_id 0 (first 5 dims): {[round(x, 4) for x in output_demo[0, 0, :5].tolist()]}\")\n",
        "# For input_id=1, we expect output to be influenced by 'all zeros'\n",
        "print(f\"Output for input_id 1 (first 5 dims): {[round(x, 4) for x in output_demo[0, 1, :5].tolist()]}\")\n",
        "# For input_id=2, we expect output to be influenced by 'all negative ones'\n",
        "print(f\"Output for input_id 2 (first 5 dims): {[round(x, 4) for x in output_demo[0, 2, :5].tolist()]}\")\n",
        "\n",
        "print(\"\\nObservation: The output hidden states for each position reflect the distinct values manually set in the memory table for their corresponding input IDs. This demonstrates how the EngramModule can inject specific, contextually relevant information from its memory into the main data stream, even when the initial hidden state is neutral.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demonstrating the value of EngramModule:\n",
            "Memory table entries 0, 13, and 26 have been set to distinct values.\n",
            "Gating and Merge Projection modified to be identity mappings.\n",
            "Initial mock hidden state (first element of first item): 0.0000\n",
            "Mock input IDs: [[0, 1, 2]]\n",
            "\n",
            "Output after EngramModule forward pass:\n",
            "--------------------------------------\n",
            "Output for input_id 0 (first 5 dims): [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "Output for input_id 1 (first 5 dims): [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Output for input_id 2 (first 5 dims): [-1.0, -1.0, -1.0, -1.0, -1.0]\n",
            "\n",
            "Observation: The output hidden states for each position reflect the distinct values manually set in the memory table for their corresponding input IDs. This demonstrates how the EngramModule can inject specific, contextually relevant information from its memory into the main data stream, even when the initial hidden state is neutral.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aeda402"
      },
      "source": [
        "### Conceptual Training Loop Steps:\n",
        "\n",
        "1.  **Initialize Model**: Create an instance of your `EngramModule`.\n",
        "2.  **Initialize Loss Function**: Choose an appropriate loss function for your task.\n",
        "3.  **Initialize Optimizer**: Tell the optimizer which model parameters to update.\n",
        "4.  **Loop over epochs**: An epoch is one full pass through your entire training dataset.\n",
        "    a.  **Loop over batches**: Divide your data into smaller batches.\n",
        "        i.  **Forward Pass**: Feed a batch of inputs through the `EngramModule` to get predictions.\n",
        "        ii. **Calculate Loss**: Compare predictions to true targets using the loss function.\n",
        "        iii. **Zero Gradients**: Clear out old gradients from the previous step.\n",
        "        iv. **Backward Pass (Backpropagation)**: Calculate gradients (how much each parameter contributed to the loss).\n",
        "        v.  **Optimizer Step**: Adjust model parameters based on the gradients to reduce the loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53b3fff4",
        "outputId": "e8a5e5ae-22b2-49eb-d842-36749308d5c1"
      },
      "source": [
        "# Cell 53b3fff4\n",
        "import torch.optim as optim\n",
        "\n",
        "# Re-initialize a fresh EngramModule for training demonstration\n",
        "# We will use the default n_heads=4 to show a more typical scenario\n",
        "model_for_training = EngramModule(n_heads=4).to(device)\n",
        "\n",
        "# --- 1. Create Mock Data for Demonstration ---\n",
        "# Let's say we want to learn to store and retrieve specific numerical vectors for given input IDs\n",
        "# We'll create a simple mapping: input_id -> target_vector\n",
        "\n",
        "# Number of unique items we want to store/retrieve\n",
        "num_items = 5\n",
        "\n",
        "# Generate mock input_ids (e.g., word tokens)\n",
        "mock_train_ids = torch.randint(0, 100, (32, num_items)).to(device) # Batch size 32, seq_len 5\n",
        "\n",
        "# Generate mock hidden_states (e.g., from a preceding Transformer layer)\n",
        "mock_train_hidden = torch.randn(32, num_items, model_for_training.d_model).to(device)\n",
        "\n",
        "# Generate target 'embeddings' that the EngramModule should output when given these ids\n",
        "# For simplicity, target embedding for input_id=k is a vector of all 'k's\n",
        "target_embeddings = torch.zeros(32, num_items, model_for_training.d_model).to(device)\n",
        "for i in range(num_items):\n",
        "    # For the i-th position in the sequence, let its target be `mock_train_ids[batch_idx, i]`\n",
        "    # We'll use the actual input ID as the target scalar for this simplified example\n",
        "    # This means the model should learn to output a vector of 'input_id's\n",
        "    current_input_ids_batch = mock_train_ids[:, i].unsqueeze(1) # [Batch, 1]\n",
        "    target_val = current_input_ids_batch.float() # [Batch, 1]\n",
        "    target_embeddings[:, i, :] = target_val.expand(-1, model_for_training.d_model)\n",
        "\n",
        "print(f\"Mock Training Data Prepared:\\n  Input IDs shape: {mock_train_ids.shape}\\n  Hidden States shape: {mock_train_hidden.shape}\\n  Target Embeddings shape: {target_embeddings.shape}\")\n",
        "\n",
        "# --- 2. Define Loss Function ---\n",
        "# Mean Squared Error (MSE) is suitable for learning to output specific target vectors\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# --- 3. Define Optimizer ---\n",
        "# Adam optimizer will update the learnable parameters of our model\n",
        "optimizer = optim.Adam(model_for_training.parameters(), lr=0.001)\n",
        "\n",
        "# --- 4. Training Loop (minimal example) ---\n",
        "num_epochs = 500 # Increased epochs for better demonstration\n",
        "\n",
        "print(f\"\\nStarting a simple training loop for {num_epochs} epochs...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_for_training.train() # Set the model to training mode\n",
        "\n",
        "    # Forward pass\n",
        "    output = model_for_training(mock_train_hidden, mock_train_ids)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(output, target_embeddings)\n",
        "\n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 50 == 0 or epoch == 0: # Print loss every 50 epochs or at the start\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete!\\n\")\n",
        "\n",
        "# --- Optional: Verify learning (conceptually) ---\n",
        "# After training, the memory_table entries should have changed to better represent the target outputs\n",
        "# for the hash-mapped input_ids. We can inspect a retrieved output.\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model_for_training.eval()\n",
        "with torch.no_grad(): # No need to calculate gradients during inference\n",
        "    # Take the first item from our mock data\n",
        "    sample_hidden = mock_train_hidden[0:1, :, :]\n",
        "    sample_ids = mock_train_ids[0:1, :]\n",
        "    sample_target = target_embeddings[0:1, :, :]\n",
        "\n",
        "    retrieved_output = model_for_training(sample_hidden, sample_ids)\n",
        "\n",
        "    print(\"Verification after training (first sample):\")\n",
        "    print(f\"  Input ID (first element): {sample_ids[0, 0].item()}\")\n",
        "    print(f\"  Target (first element, first 5 dims): {[round(x, 4) for x in sample_target[0, 0, :5].tolist()]}\")\n",
        "    print(f\"  Output (first element, first 5 dims): {[round(x, 4) for x in retrieved_output[0, 0, :5].tolist()]}\")\n",
        "    print(\"\\nObservation: The output after even a few epochs should show values closer to the target values compared to random initialization, indicating that the EngramModule's parameters (especially the memory table) have started to learn.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mock Training Data Prepared:\n",
            "  Input IDs shape: torch.Size([32, 5])\n",
            "  Hidden States shape: torch.Size([32, 5, 512])\n",
            "  Target Embeddings shape: torch.Size([32, 5, 512])\n",
            "\n",
            "Starting a simple training loop for 500 epochs...\n",
            "Epoch 1/500, Loss: 3501.6450\n",
            "Epoch 50/500, Loss: 3203.0532\n",
            "Epoch 100/500, Loss: 2375.9204\n",
            "Epoch 150/500, Loss: 1376.3779\n",
            "Epoch 200/500, Loss: 631.4255\n",
            "Epoch 250/500, Loss: 238.7297\n",
            "Epoch 300/500, Loss: 82.6029\n",
            "Epoch 350/500, Loss: 28.9877\n",
            "Epoch 400/500, Loss: 10.9647\n",
            "Epoch 450/500, Loss: 4.7411\n",
            "Epoch 500/500, Loss: 2.4118\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Verification after training (first sample):\n",
            "  Input ID (first element): 77\n",
            "  Target (first element, first 5 dims): [77.0, 77.0, 77.0, 77.0, 77.0]\n",
            "  Output (first element, first 5 dims): [77.7014, 77.5675, 77.1594, 77.327, 76.8516]\n",
            "\n",
            "Observation: The output after even a few epochs should show values closer to the target values compared to random initialization, indicating that the EngramModule's parameters (especially the memory table) have started to learn.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a28b389",
        "outputId": "a8212866-75bd-4322-e8db-1efd0db7fa17"
      },
      "source": [
        "# Cell 4a28b389\n",
        "import math\n",
        "\n",
        "# Create a new instance of EngramModule for this demonstration\n",
        "# We set n_heads=1 to avoid multi-head averaging for simplicity\n",
        "model_direct = EngramModule(n_heads=1).to(device)\n",
        "\n",
        "print(\"--- Modified EngramModule for Direct Retrieval (Animal Embeddings) ---\")\n",
        "\n",
        "# 1. Manually set specific entries in the memory_table with distinct numerical vectors\n",
        "#    representing 'dog', 'cat', 'horse', 'cow'.\n",
        "#    Based on multi_head_hash:\n",
        "#    input_id 0 -> index 0\n",
        "#    input_id 1 -> index 13\n",
        "#    input_id 2 -> index 26\n",
        "#    input_id 3 -> index 39\n",
        "model_direct.memory_table.data[0, :] = 1.0  # Represents 'dog' (all ones)\n",
        "model_direct.memory_table.data[13, :] = 2.0 # Represents 'cat' (all twos)\n",
        "model_direct.memory_table.data[26, :] = 3.0 # Represents 'horse' (all threes)\n",
        "model_direct.memory_table.data[39, :] = 4.0 # Represents 'cow' (all fours)\n",
        "\n",
        "print(\"Memory table entries 0, 13, 26, and 39 have been set to distinct values.\")\n",
        "print(\"These vectors conceptually represent 'dog' (1s), 'cat' (2s), 'horse' (3s), and 'cow' (4s).\")\n",
        "\n",
        "# 2. Modify the gate to effectively be an identity (output ~1.0 after sigmoid)\n",
        "# Set weights to 0 and bias to a large positive number\n",
        "model_direct.gate.weight.data.zero_()\n",
        "model_direct.gate.bias.data.fill_(10.0) # Large bias -> sigmoid output close to 1\n",
        "\n",
        "print(\"Gating mechanism modified to pass through most of the memory.\")\n",
        "\n",
        "# 3. Modify the merge_proj to be an identity mapping\n",
        "# Set weight to identity matrix and bias to zero\n",
        "model_direct.merge_proj.weight.data.copy_(torch.eye(model_direct.d_model))\n",
        "model_direct.merge_proj.bias.data.zero_()\n",
        "\n",
        "print(\"Merge projection modified to be an identity mapping.\")\n",
        "\n",
        "# Prepare mock inputs (neutral hidden states and input_ids for our animals)\n",
        "mock_hidden_demo_direct = torch.zeros(1, 4, model_direct.d_model).to(device) # 4 animals\n",
        "mock_ids_demo_direct = torch.tensor([[0, 1, 2, 3]]).to(device) # Input IDs to query the animals\n",
        "\n",
        "# Perform forward pass with the modified model\n",
        "output_direct = model_direct(mock_hidden_demo_direct, mock_ids_demo_direct)\n",
        "\n",
        "print(\"\\nOutput after Modified EngramModule forward pass (Animal Embeddings):\")\n",
        "print(\"------------------------------------------------------------------\")\n",
        "\n",
        "# Print a slice of the output to observe the influence\n",
        "print(f\"Output for input_id 0 (representing 'dog', first 5 dims):\")\n",
        "for val in output_direct[0, 0, :5].tolist():\n",
        "    print(f\"  {val}\")\n",
        "\n",
        "print(f\"Output for input_id 1 (representing 'cat', first 5 dims):\")\n",
        "for val in output_direct[0, 1, :5].tolist():\n",
        "    print(f\"  {val}\")\n",
        "\n",
        "print(f\"Output for input_id 2 (representing 'horse', first 5 dims):\")\n",
        "for val in output_direct[0, 2, :5].tolist():\n",
        "    print(f\"  {val}\")\n",
        "\n",
        "print(f\"Output for input_id 3 (representing 'cow', first 5 dims):\")\n",
        "for val in output_direct[0, 3, :5].tolist():\n",
        "    print(f\"  {val}\")\n",
        "\n",
        "print(\"\\nObservation: The output values for each input ID now closely reflect the distinct numerical vectors stored (\")\n",
        "print(\"1.0 for 'dog', 2.0 for 'cat', 3.0 for 'horse', and 4.0 for 'cow' respectively),\")\n",
        "print(\"demonstrating the conceptual storage and retrieval of 'embeddings' for words.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Modified EngramModule for Direct Retrieval (Animal Embeddings) ---\n",
            "Memory table entries 0, 13, 26, and 39 have been set to distinct values.\n",
            "These vectors conceptually represent 'dog' (1s), 'cat' (2s), 'horse' (3s), and 'cow' (4s).\n",
            "Gating mechanism modified to pass through most of the memory.\n",
            "Merge projection modified to be an identity mapping.\n",
            "\n",
            "Output after Modified EngramModule forward pass (Animal Embeddings):\n",
            "------------------------------------------------------------------\n",
            "Output for input_id 0 (representing 'dog', first 5 dims):\n",
            "  0.9999545812606812\n",
            "  0.9999545812606812\n",
            "  0.9999545812606812\n",
            "  0.9999545812606812\n",
            "  0.9999545812606812\n",
            "Output for input_id 1 (representing 'cat', first 5 dims):\n",
            "  1.9999091625213623\n",
            "  1.9999091625213623\n",
            "  1.9999091625213623\n",
            "  1.9999091625213623\n",
            "  1.9999091625213623\n",
            "Output for input_id 2 (representing 'horse', first 5 dims):\n",
            "  2.999863624572754\n",
            "  2.999863624572754\n",
            "  2.999863624572754\n",
            "  2.999863624572754\n",
            "  2.999863624572754\n",
            "Output for input_id 3 (representing 'cow', first 5 dims):\n",
            "  3.9998183250427246\n",
            "  3.9998183250427246\n",
            "  3.9998183250427246\n",
            "  3.9998183250427246\n",
            "  3.9998183250427246\n",
            "\n",
            "Observation: The output values for each input ID now closely reflect the distinct numerical vectors stored (\n",
            "1.0 for 'dog', 2.0 for 'cat', 3.0 for 'horse', and 4.0 for 'cow' respectively),\n",
            "demonstrating the conceptual storage and retrieval of 'embeddings' for words.\n"
          ]
        }
      ]
    }
  ]
}